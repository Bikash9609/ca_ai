# CA AI Backend Environment Variables

# Anthropic Claude API Key (optional)
# Required for Claude LLM integration
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# Ollama Configuration (optional)
# Only needed if using Ollama as LLM provider
# Default: http://localhost:11434
OLLAMA_URL=http://localhost:11434

# Ollama Model Name (optional)
# Default: llama2
OLLAMA_MODEL=llama2

# Workspace Path (optional)
# Default: ~/ca-ai-workspaces
# Custom path where client data and databases are stored
CA_AI_WORKSPACE_PATH='/Users/bikashtiwari/Documents/Projects/ca_ai/.temp_data'

# Google Gemini API Key (optional)
# Required for Gemini LLM integration
# Get your API key from: https://aistudio.google.com/apikey
GEMINI_API_KEY=

# Gemini Model Name (optional)
# Default: gemini-2.5-flash
# Options: gemini-2.5-flash, gemini-2.5-pro, etc.
GEMINI_MODEL=gemini-2.5-flash

# Groq API Key (optional)
# Required for Groq LLM integration
# Get your API key from: https://console.groq.com/keys
GROQ_API_KEY=

# Groq Model Name (optional)
# Default: llama-3.3-70b-versatile
# Options: llama-3.3-70b-versatile, mixtral-8x7b-32768, etc.
GROQ_MODEL=llama-3.3-70b-versatile

# OpenRouter API Key (optional)
# Required for OpenRouter LLM integration
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=

# OpenRouter Model Name (optional)
# Default: openai/gpt-4o
# Options: openai/gpt-4o, anthropic/claude-3.5-sonnet, etc.
# See available models at: https://openrouter.ai/models
OPENROUTER_MODEL=openai/gpt-4o
